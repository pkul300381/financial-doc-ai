# Financial Document Extraction PoC

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

Intelligent financial document extraction system with OCR, LLM-based extraction, RAG insights, and ML anomaly detection.

## ğŸ¯ Features

- **ğŸ“„ Document Processing**: OCR extraction from PDFs and images using Tesseract
- **ğŸ“Š Table Extraction**: Automated table detection with Camelot and pdfplumber
- **ğŸ¤– LLM Extraction**: Structured data extraction using OpenAI GPT-4
- **ğŸ” Semantic Search**: Vector-based document search with ChromaDB
- **ğŸ’¬ RAG Q&A**: Natural language queries over documents
- **ğŸš¨ Anomaly Detection**: ML-based outlier detection with Isolation Forest
- **ğŸ“ˆ Trend Analysis**: Time series forecasting with Prophet
- **ğŸŒ REST API**: FastAPI endpoints for all operations
- **ğŸ“Š Monitoring**: Prometheus metrics and health checks
- **ğŸ³ Docker**: Containerized deployment with CI/CD

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Document   â”‚â”€â”€â”€â”€â–¶â”‚     OCR      â”‚â”€â”€â”€â”€â–¶â”‚     LLM     â”‚
â”‚   Upload    â”‚     â”‚ Preprocessingâ”‚     â”‚ Extraction  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚
                                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Insights  â”‚â—€â”€â”€â”€â”€â”‚  Vector DB   â”‚â—€â”€â”€â”€â”€â”‚  Structured â”‚
â”‚  & Anomaly  â”‚     â”‚   (Chroma)   â”‚     â”‚    Data     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

- **Ingestion Layer**: File upload, S3 storage, metadata management
- **OCR Engine**: Tesseract, pdf2image, OpenCV preprocessing
- **Extraction Engine**: LangChain + OpenAI for structured extraction
- **Vector Store**: ChromaDB for embeddings and semantic search
- **Analytics**: Isolation Forest + Prophet for anomaly/trend detection
- **API Layer**: FastAPI with Prometheus monitoring

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- Tesseract OCR
- OpenAI API key
- Docker (optional)

### Installation

```cmd
REM Clone repository
git clone <repository-url>
cd Financial-poc

REM Create virtual environment
python -m venv venv
venv\Scripts\activate

REM Install dependencies
pip install -r requirements.txt

REM Configure environment
copy .env.example .env
REM Edit .env and add your OPENAI_API_KEY
```

### Running Locally

```cmd
REM Start API server
python api.py

REM Or run pipeline directly
python poc_pipeline.py
```

API will be available at `http://localhost:8000`

### Docker Deployment

```cmd
docker build -t financial-poc .
docker run -d -p 8000:8000 --name financial-poc financial-poc
```

## ğŸ“– Usage

### Upload Document

```python
import requests

response = requests.post(
    "http://localhost:8000/api/v1/documents/upload",
    files={"file": open("invoice.pdf", "rb")}
)
doc_id = response.json()["document_id"]
```

### Query Documents

```python
response = requests.post(
    "http://localhost:8000/api/v1/query",
    json={
        "query": "What is the total amount of all invoices?",
        "top_k": 5
    }
)
print(response.json()["answer"])
```

### Detect Anomalies

```python
response = requests.get("http://localhost:8000/api/v1/anomalies")
anomalies = response.json()
for anomaly in anomalies:
    print(f"{anomaly['severity']}: {anomaly['description']}")
```

See [API Documentation](docs/API.md) for complete endpoint reference.

## ğŸ§ª Testing

```cmd
REM Run all tests
pytest tests/ -v

REM Run with coverage
pytest tests/ --cov=src --cov-report=html

REM Run specific test file
pytest tests/test_pipeline.py -v
```

## ğŸ“Š Monitoring

### Metrics Endpoint

Prometheus metrics available at `/metrics`:
- `documents_uploaded_total`: Total documents processed
- `document_processing_seconds`: Processing time histogram
- `queries_total`: Total queries executed
- `anomalies_detected_total`: Total anomalies found

### Health Check

```bash
curl http://localhost:8000/health
```

## ğŸ¢ Project Structure

```
Financial-poc/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic models
â”‚   â”œâ”€â”€ ocr/
â”‚   â”‚   â””â”€â”€ preprocessor.py     # OCR & preprocessing
â”‚   â”œâ”€â”€ extraction/
â”‚   â”‚   â””â”€â”€ llm_extractor.py    # LLM-based extraction
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â””â”€â”€ rag_engine.py       # Vector DB & RAG
â”‚   â”œâ”€â”€ anomaly/
â”‚   â”‚   â””â”€â”€ detector.py         # Anomaly detection
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ helpers.py          # Utilities
â”‚   â””â”€â”€ config.py               # Configuration
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_pipeline.py        # Unit tests
â”‚   â””â”€â”€ integration/
â”‚       â””â”€â”€ test_api.py         # API tests
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ API.md                  # API documentation
â”‚   â””â”€â”€ DEPLOYMENT.md           # Deployment guide
â”œâ”€â”€ api.py                      # FastAPI application
â”œâ”€â”€ poc_pipeline.py             # Main pipeline
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ Dockerfile                  # Docker configuration
â”œâ”€â”€ Jenkinsfile                 # CI/CD pipeline
â””â”€â”€ README.md                   # This file
```

## ğŸ”§ Configuration

Key environment variables (see `.env.example`):

- `OPENAI_API_KEY`: OpenAI API key (required)
- `DATABASE_URL`: PostgreSQL connection string
- `VECTOR_DB_PATH`: ChromaDB storage path
- `S3_BUCKET_NAME`: S3 bucket for document storage
- `TESSERACT_PATH`: Path to Tesseract binary

## ğŸ“ˆ Performance

Typical processing times (on standard hardware):
- **OCR**: 2-5 seconds per page
- **LLM Extraction**: 3-8 seconds per document
- **Vectorization**: 1-2 seconds per document
- **Query**: 0.5-2 seconds

## ğŸ”’ Security

- API key authentication
- PII masking in logs
- Input validation on all endpoints
- Dependencies scanned with Safety and Bandit
- Container runs as non-root user

See [Security Checklist](docs/DEPLOYMENT.md#security-checklist) for details.

## ğŸš¢ CI/CD

Jenkins pipeline includes:
1. Code quality checks (Black, Flake8, MyPy)
2. Unit tests with coverage
3. Security scans
4. Docker image build and test
5. Integration tests
6. Deployment to staging
7. Smoke tests

## ğŸ—ºï¸ Roadmap

- [ ] Add support for more document types (receipts, tax forms)
- [ ] Implement async processing with Celery
- [ ] Add support for other LLM providers (Anthropic, local models)
- [ ] Build Streamlit UI for document viewer
- [ ] Add support for batch processing
- [ ] Implement document comparison features
- [ ] Add multi-language support

## ğŸ“š Documentation

- [API Documentation](docs/API.md)
- [Deployment Guide](docs/DEPLOYMENT.md)
- [Architecture Deep Dive](docs/ARCHITECTURE.md) (coming soon)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests
5. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- OpenAI for GPT-4 and embeddings
- Tesseract OCR
- LangChain framework
- FastAPI framework
- ChromaDB vector database

## ğŸ“ Support

For issues and questions:
- Create an issue on GitHub
- Check existing documentation
- Review test files for usage examples

---

**Built with â¤ï¸ for financial document intelligence**